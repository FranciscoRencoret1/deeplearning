{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "AlexNet.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "[View in Colaboratory](https://colab.research.google.com/github/FranciscoRencoret1/deeplearning/blob/master/AlexNet.ipynb)"
      ]
    },
    {
      "metadata": {
        "id": "WDgSKsiv8_PW",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "# Tarea 1 Deep Learning\n",
        "\n",
        "Francisco Rencoret (FranciscoRencoret1) - Raimundo Manterola (rmant)"
      ]
    },
    {
      "metadata": {
        "id": "gaRMhhinpb6V",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "1687972d-88f5-4e77-b63c-4fe53fdf97ab"
      },
      "cell_type": "code",
      "source": [
        "!wget https://www.dropbox.com/s/c0d7npcg1yysnux/MIT-10-Classes.zip?dl=0\n",
        "!unzip -q MIT-10-Classes.zip?dl=0"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "--2018-04-21 19:34:28--  https://www.dropbox.com/s/c0d7npcg1yysnux/MIT-10-Classes.zip?dl=0\n",
            "Resolving www.dropbox.com (www.dropbox.com)... 162.125.7.1, 2620:100:6016:1::a27d:101\n",
            "Connecting to www.dropbox.com (www.dropbox.com)|162.125.7.1|:443... connected.\n",
            "HTTP request sent, awaiting response... 302 Found\n",
            "Location: https://dl.dropboxusercontent.com/content_link/L5S6Z1kwskaXIroZmvk3ElWSovtMspDVicM7d1Rdc0zQAleCbOAFD96dtiofctEw/file [following]\n",
            "--2018-04-21 19:34:29--  https://dl.dropboxusercontent.com/content_link/L5S6Z1kwskaXIroZmvk3ElWSovtMspDVicM7d1Rdc0zQAleCbOAFD96dtiofctEw/file\n",
            "Resolving dl.dropboxusercontent.com (dl.dropboxusercontent.com)... 162.125.7.6, 2620:100:6016:6::a27d:106\n",
            "Connecting to dl.dropboxusercontent.com (dl.dropboxusercontent.com)|162.125.7.6|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 139459806 (133M) [application/zip]\n",
            "Saving to: ‘MIT-10-Classes.zip?dl=0’\n",
            "\n",
            "MIT-10-Classes.zip? 100%[===================>] 133.00M  33.7MB/s    in 4.0s    \n",
            "\n",
            "2018-04-21 19:34:34 (33.7 MB/s) - ‘MIT-10-Classes.zip?dl=0’ saved [139459806/139459806]\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "RwWQW2-dpisq",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Definicion de librerias con la funciones que seran utilizadas por Keras.\n",
        "from keras.layers import Activation, Dense, Flatten, Dropout\n",
        "from keras.models import Sequential\n",
        "from keras.layers.convolutional import Convolution2D, ZeroPadding2D\n",
        "from keras.layers.normalization import BatchNormalization\n",
        "from keras.layers.pooling import MaxPooling2D\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array\n",
        "from keras.utils import to_categorical"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EAJfvrMUl0Pm",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fde898fe-18bc-4180-e82c-34d9a7dc8337"
      },
      "cell_type": "code",
      "source": [
        "#Definicion de contenedor y primera capa de AlexNet.\n",
        "modelAlexNet = Sequential()\n",
        "modelAlexNet.add(ZeroPadding2D((2,2), input_shape=(224, 224, 3)))\n",
        "modelAlexNet.add(Convolution2D(96, (11,11), strides=(4,4), padding=\"valid\"))\n",
        "modelAlexNet.add(Activation(activation=\"relu\"))\n",
        "output_shape_first_layer = modelAlexNet.output_shape\n",
        "print('Los mapas de activación de la capa 1 de convolción tienen tamaño: {}'.format(output_shape_first_layer))\n",
        "modelAlexNet.add(BatchNormalization())\n",
        "modelAlexNet.add(MaxPooling2D((3,3), strides=(2,2)))"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Los mapas de activación de la capa 1 de convolción tienen tamaño: (None, 55, 55, 96)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "JKwyKBFDmMix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5efdee66-0cf6-493b-96a6-596be774b9fa"
      },
      "cell_type": "code",
      "source": [
        "#Definicion de la segunda capa de AlexNet.\n",
        "modelAlexNet.add(ZeroPadding2D((2,2)))\n",
        "modelAlexNet.add(Convolution2D(256, (5, 5), padding=\"valid\"))\n",
        "modelAlexNet.add(Activation(activation=\"relu\"))\n",
        "output_shape_second_layer = modelAlexNet.output_shape\n",
        "print('Los mapas de activación de la capa 2 de convolción tienen tamaño: {}'.format(output_shape_second_layer))\n",
        "modelAlexNet.add(BatchNormalization())\n",
        "modelAlexNet.add(MaxPooling2D((3,3), strides=(2,2)))"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Los mapas de activación de la capa 2 de convolción tienen tamaño: (None, 27, 27, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "eOCC80OE9IPb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Actividad 1"
      ]
    },
    {
      "metadata": {
        "id": "LBwKcWM79MKY",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Notamos que la primera capa de AlexNet es de tamaño (55, 55, 96). Como podemos ver, nuestra primera capa tiene las mismas dimensiones:"
      ]
    },
    {
      "metadata": {
        "id": "QJu5i4Sm9Nal",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b1738082-1dcb-434b-d036-7f52fa2b3ede"
      },
      "cell_type": "code",
      "source": [
        "output_shape_first_layer"
      ],
      "execution_count": 99,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 55, 55, 96)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 99
        }
      ]
    },
    {
      "metadata": {
        "id": "TuL7FlC79Ri4",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "La segunda capa de AlexNet es de tamanño (27, 27, 256). Nuestra segunda capa tiene las mismas dimensiones"
      ]
    },
    {
      "metadata": {
        "id": "QPwXzTNH9S4g",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "cc1e6074-2f35-42f6-f7c9-0d181690cc3a"
      },
      "cell_type": "code",
      "source": [
        "output_shape_second_layer"
      ],
      "execution_count": 100,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 27, 27, 256)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 100
        }
      ]
    },
    {
      "metadata": {
        "id": "fjjIvn9c9YHk",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Ahora, vamos a mostrar un resumen de la red creada"
      ]
    },
    {
      "metadata": {
        "id": "p6HtNizz9akr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        },
        "outputId": "f6ad91e1-fbed-4bda-b9de-6ec8c28048c6"
      },
      "cell_type": "code",
      "source": [
        "modelAlexNet.summary()"
      ],
      "execution_count": 101,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "zero_padding2d_1 (ZeroPaddin (None, 228, 228, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 55, 55, 96)        34944     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 55, 55, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 55, 55, 96)        384       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 96)        0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPaddin (None, 31, 31, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 27, 27, 256)       614656    \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 27, 27, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 27, 27, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 256)       0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPaddin (None, 15, 15, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 13, 13, 384)       885120    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 13, 13, 384)       0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPaddin (None, 15, 15, 384)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 384)       1327488   \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 13, 13, 384)       0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPaddin (None, 15, 15, 384)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 13, 13, 256)       884992    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 13, 13, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              37752832  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                40970     \n",
            "=================================================================\n",
            "Total params: 58,323,722\n",
            "Trainable params: 58,323,018\n",
            "Non-trainable params: 704\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "BTjHG2jg9deT",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Podemos notar que en la primera capa, teniamos filtros de tamaño 11 x 11 x 3 + 1 pesos (11 x 11 con profundidad 3 + el bias). Ahora, como la primera capa tiene 96 mapas de activacion, vamos a tener 96 de estos filtros, por lo que en la primera capa se tiene (11 x 11 x 3 + 1) x 96 = 34,944 pesos. Podemos ver que esto coincide con el valor de la segunda fila de la tabla.\n",
        "\n",
        "La segunda capa tiene filtros de 5 x 5 x 96 + 1 (5 x 5 con profundidad 96 + un bias) y tenemos 256 mapas de activacion, por lo que en total la capa tiene (5 x 5 x 96 + 1) x 256 = 614,656. Esto coincide con el valor de la septima fila de la tabla.\n",
        "\n",
        "Por otra parte, podemos notar que el batch normaliation en ambos casos calcula 4 parametros. Como la normalización consiste en:\n",
        "\n",
        "$$\\begin{equation}\n",
        "\\hat{a} =  \\frac{x - \\mu}{\\sigma}\n",
        "\\end{equation}$$\n",
        "\n",
        "y luego\n",
        "\n",
        "$$\\begin{equation}\n",
        "\\hat{x} =  \\varphi \\hat{a} + \\beta\n",
        "\\end{equation}$$\n",
        "\n",
        "la red debe calcular y almacenar $\\mu$ y $\\sigma$ (parametros no entrenables). Por otro lado, debe calcular y entrenar a $\\varphi$ y $\\beta$, por lo que por cada mapa de activacion almacena 4 pesos pero solo entrena 2. En total, primer batch tiene 96 x 4 = 384 pesos (192 entrenables) y el segundo 256 x 4 = 1024 (512 entrenables).\n",
        "\n",
        "En resumen:\n",
        "Pesos: 34,944 + 384 + 614,656 + 1024 = 651,008\n",
        "Pesos entrenables: 34,944 + 192 + 614,656 + 512 = 650,304"
      ]
    },
    {
      "metadata": {
        "id": "2bh_7ib69mCa",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Actividad 2"
      ]
    },
    {
      "metadata": {
        "id": "HwtwFVksmOwa",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7f63205b-5255-4fcf-eea4-86d0c8e38580"
      },
      "cell_type": "code",
      "source": [
        "#Definicion de la tercera capa de AlexNet\n",
        "modelAlexNet.add(ZeroPadding2D((1,1)))\n",
        "modelAlexNet.add(Convolution2D(384, (3, 3), strides=(1,1), padding=\"valid\"))\n",
        "modelAlexNet.add(Activation(activation=\"relu\"))\n",
        "output_shape_third_layer = modelAlexNet.output_shape\n",
        "print('Los mapas de activación de la capa 3 de convolción tienen tamaño: {}'.format(output_shape_third_layer))"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Los mapas de activación de la capa 3 de convolción tienen tamaño: (None, 13, 13, 384)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "MvDpht6p9qtE",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Verificamos que tenga las mismas dimensiones"
      ]
    },
    {
      "metadata": {
        "id": "_xkTrsDe9raD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "fec150de-3292-4e3e-961e-0ffb001f46a1"
      },
      "cell_type": "code",
      "source": [
        "output_shape_third_layer"
      ],
      "execution_count": 102,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 13, 13, 384)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 102
        }
      ]
    },
    {
      "metadata": {
        "id": "H57liRte9vPy",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Volvemos a revisar el resumen de la red"
      ]
    },
    {
      "metadata": {
        "id": "0a273orG9wzC",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1020
        },
        "outputId": "1e9ea174-4a94-440e-ee6a-f63be56020d7"
      },
      "cell_type": "code",
      "source": [
        "modelAlexNet.summary()"
      ],
      "execution_count": 103,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "zero_padding2d_1 (ZeroPaddin (None, 228, 228, 3)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 55, 55, 96)        34944     \n",
            "_________________________________________________________________\n",
            "activation_1 (Activation)    (None, 55, 55, 96)        0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_1 (Batch (None, 55, 55, 96)        384       \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 27, 27, 96)        0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_2 (ZeroPaddin (None, 31, 31, 96)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 27, 27, 256)       614656    \n",
            "_________________________________________________________________\n",
            "activation_2 (Activation)    (None, 27, 27, 256)       0         \n",
            "_________________________________________________________________\n",
            "batch_normalization_2 (Batch (None, 27, 27, 256)       1024      \n",
            "_________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2 (None, 13, 13, 256)       0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_3 (ZeroPaddin (None, 15, 15, 256)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_3 (Conv2D)            (None, 13, 13, 384)       885120    \n",
            "_________________________________________________________________\n",
            "activation_3 (Activation)    (None, 13, 13, 384)       0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_4 (ZeroPaddin (None, 15, 15, 384)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_4 (Conv2D)            (None, 13, 13, 384)       1327488   \n",
            "_________________________________________________________________\n",
            "activation_4 (Activation)    (None, 13, 13, 384)       0         \n",
            "_________________________________________________________________\n",
            "zero_padding2d_5 (ZeroPaddin (None, 15, 15, 384)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_5 (Conv2D)            (None, 13, 13, 256)       884992    \n",
            "_________________________________________________________________\n",
            "activation_5 (Activation)    (None, 13, 13, 256)       0         \n",
            "_________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2 (None, 6, 6, 256)         0         \n",
            "_________________________________________________________________\n",
            "flatten_1 (Flatten)          (None, 9216)              0         \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 4096)              37752832  \n",
            "_________________________________________________________________\n",
            "dropout_1 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 4096)              16781312  \n",
            "_________________________________________________________________\n",
            "dropout_2 (Dropout)          (None, 4096)              0         \n",
            "_________________________________________________________________\n",
            "dense_3 (Dense)              (None, 10)                40970     \n",
            "=================================================================\n",
            "Total params: 58,323,722\n",
            "Trainable params: 58,323,018\n",
            "Non-trainable params: 704\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "1wcqgPVb90xH",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Actividad 3"
      ]
    },
    {
      "metadata": {
        "id": "gw8XwG-FmRY9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "f9582625-7a65-4675-ecb0-6c9b50a69426"
      },
      "cell_type": "code",
      "source": [
        "#Definicion de la cuarta capa de AlexNet\n",
        "modelAlexNet.add(ZeroPadding2D((1,1)))\n",
        "modelAlexNet.add(Convolution2D(384, (3, 3), strides=(1,1), padding=\"valid\"))\n",
        "modelAlexNet.add(Activation(activation=\"relu\"))\n",
        "output_shape_fourth_layer = modelAlexNet.output_shape\n",
        "print('Los mapas de activación de la capa 4 de convolción tienen tamaño: {}'.format(output_shape_fourth_layer))"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Los mapas de activación de la capa 4 de convolción tienen tamaño: (None, 13, 13, 384)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "OBN5fbkKmTx6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7bf807ab-de6d-4cfd-a53d-3633d613aa33"
      },
      "cell_type": "code",
      "source": [
        "#Definicion de la quinta capa de AlexNet\n",
        "modelAlexNet.add(ZeroPadding2D((1,1)))\n",
        "modelAlexNet.add(Convolution2D(256, (3, 3), strides=(1,1), padding=\"valid\"))\n",
        "modelAlexNet.add(Activation(activation=\"relu\"))\n",
        "output_shape_fifth_layer = modelAlexNet.output_shape\n",
        "print('Los mapas de activación de la capa 5 de convolción tienen tamaño: {}'.format(output_shape_fifth_layer))\n",
        "modelAlexNet.add(MaxPooling2D((3,3), strides=(2,2)))"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Los mapas de activación de la capa 5 de convolción tienen tamaño: (None, 13, 13, 256)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "jyujRg6c95Xv",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Nuevamente verificamos que las dimensiones son correctas. Al igual que la capa 3, las dimensiones de la capa 4 son (13, 13, 384). La quinta capa tiene dimensiones (13, 13, 256). Viendo las dimensiones de AlexNet, notamos que coinciden. Ahora, revisemos el resumen del modelo para ver la cantidad de parametros:"
      ]
    },
    {
      "metadata": {
        "id": "raRDJNoq96-6",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "modelAlexNet.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "jJ1V6osP9_T6",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Podemos notar que la cuarta capa tiene más parámetros que la tercera capa, porque a pesar de tener la misma estrucutra (filtros de igual tamaño pero distinta profundidad, mapas de activación de igual tamaño), vemos que su input es distinto. La tercera recibe un input de (13, 13, 256), mientras que la cuarta recibe un input de (13, 13, 384). Por lo tanto, los filtros van a tener profundidades distintas lo que se traduce en una distinta cantidad de parametros.\n",
        "\n",
        "Por otra parte, notamos que la quinta capa recibe el mismo input que la cuarta, pero como la quinta tiene menos mapas de activación, la cantidad de parametros que debe manejar es menor. \n",
        "\n",
        "Por último, notamos que como no incluimos normalización de los batches, la cantidad de parametros no entrenables no cambia."
      ]
    },
    {
      "metadata": {
        "id": "L-DjtPzK-A3z",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Actividad 4"
      ]
    },
    {
      "metadata": {
        "id": "_E12W6D5-Dim",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Actualmente tenemos la matriz como un tensor de 3D. Como ahora tenemos que agregar las capas densas para clasificar, debemos tener la matríz como un vector de una dimensión, para luego poder hacer correctamente las conexiones con la capa densa. Para eso, usamos el comando Flatten, que lo que hace es poner en un solo vector todos los datos del tensor 3D, por lo que tendria dimensiones 6 x 6 x 256 = 9216. Agregamos la capa:"
      ]
    },
    {
      "metadata": {
        "id": "YZ73NGtrpFf7",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "modelAlexNet.add(Flatten())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Uq75_-oh-GBi",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "ecfb7299-121a-4122-c719-9b35caa4521a"
      },
      "cell_type": "code",
      "source": [
        "modelAlexNet.output_shape"
      ],
      "execution_count": 104,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(None, 10)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 104
        }
      ]
    },
    {
      "metadata": {
        "id": "zAVAHeny-H8g",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Notamos que esto efectivamente hizo lo que necesitabamos, porque ahora el modelo tiene dimensiones (1, 9216)."
      ]
    },
    {
      "metadata": {
        "id": "PlQSaMab-LFI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Actividad 5"
      ]
    },
    {
      "metadata": {
        "id": "aJQjJvNjouQU",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Definicion de la capa 6 de AlexNet\n",
        "modelAlexNet.add(Dense(4096, input_shape=(9216,), activation='relu', kernel_initializer='glorot_uniform', use_bias=True))\n",
        "modelAlexNet.add(Dropout(0.5))\n",
        "output_shape_sixth_layer = modelAlexNet.output_shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "u3xdT2Uh-Ozi",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Esta capa deberia tener dimensiones de (1, 4092), por lo que verificamos con modelAlexNet:"
      ]
    },
    {
      "metadata": {
        "id": "_gdZV59Y-QXr",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "output_shape_sixth_layer"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "dD2u2s1T-SZO",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Podemos notar que tiene las dimensiones correctas. Ahora, analizemos la cantidad de parametros que lleva la red por el momento:"
      ]
    },
    {
      "metadata": {
        "id": "i-VisYe3-S3d",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "modelAlexNet.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "w-_DgkN6-WeI",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Esta ultima capa esta compuesta por 4096 neuronas y recibe como input un vector de (1, 9216). Al ser una capa Dense (fully connected), sabemos que todas las entradas se conectan con todas la neuronas de la capa, por lo que la cantidad de parametros de la capa sería 4096 * 9216 = 37,752,832. Este es un numero muy grande, son 37 millones de parametros que provinen solamente de la primera capa del clasificador. \n",
        "\n",
        "Esto nos hace notar lo 'eficientes' en cuanto a memoria y a entrenamiento que son las CNN. Si sumamos las 5 capas de convolucion obtenemos 3,748,608 parametros, mientras que solo esta primera capa de la FC, tiene 37,752,832 parametros (debe entrenar y almacenar aprox 10 veces más).\n",
        "\n",
        "En total tenemos 41,501,440 parametros donde solo 704 no son entrenables. Esta cantidad no ha cambiado porque nuevamente no hemos agregado un batch normalization."
      ]
    },
    {
      "metadata": {
        "id": "odl6I6pL-XrR",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Actividad 6"
      ]
    },
    {
      "metadata": {
        "id": "JVqaf_GMmV4e",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Definición de la capa 7 de AlexNet\n",
        "modelAlexNet.add(Dense(4096, activation='relu', kernel_initializer='glorot_uniform', use_bias=True))\n",
        "modelAlexNet.add(Dropout(0.5))\n",
        "output_shape_seventh_layer = modelAlexNet.output_shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "eRNPExCHmZhH",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Definición de la capa 8 de AlexNet\n",
        "modelAlexNet.add(Dense(10, activation='softmax', kernel_initializer='glorot_uniform', use_bias=True))\n",
        "output_shape_eighths_layer = modelAlexNet.output_shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "8u6RVEGc-cj8",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "modelAlexNet.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Em_CF_Ky-fn-",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Cantidad de filtros: 1,376\n",
        "Cantidad total de parametros: 62,379,752\n",
        "Cantidad de parámetros entrenables: 62,379,048\n",
        "Cantidad de parámetros no entrenables: 704\n",
        "\n",
        "Resumiendo las capas:\n",
        "    1. Filtros: 96\n",
        "       Cantidad de neuronas por filtro: 55 x 55 = 3,025\n",
        "       Cantidad total de neuronas de capa: 290,400\n",
        "       Parámetros: 34,944 (filtros) + 384 (batch normalization)\n",
        "       \n",
        "    2. Filtros: 256\n",
        "       Cantidad de neuronas por filtro: 27 x 27 = 729\n",
        "       Cantidad total de neuronas de capa: 186,624\n",
        "       Parámetros: 614,656 (filtros) + 1024 (batch normalization)\n",
        "       \n",
        "    3. Filtros: 384\n",
        "       Cantidad de neuronas por filtro: 13 x 13 = 169\n",
        "       Cantidad total de neuronas de capa: 64,896\n",
        "       Parámetros: 885,120 (filtros)\n",
        "       \n",
        "    4. Filtros: 384\n",
        "       Cantidad de neuronas por filtro: 13 x 13 = 169\n",
        "       Cantidad total de neuronas de capa: 64,896\n",
        "       Parámetros: 1,327,488 (filtros)\n",
        "       \n",
        "    5. Filtros: 256\n",
        "       Cantidad de neuronas por filtro: 13 x 13 = 169\n",
        "       Cantidad total de neuronas de capa: 43,264\n",
        "       Parámetros: 884,992 (filtros)\n",
        "       \n",
        "    6. Cantidad total de neuronas de capa: 4,096\n",
        "       Parámetros: 37,752,832\n",
        "    \n",
        "    7. Cantidad total de neuronas de capa: 4,096 \n",
        "       Parámetros: 16,781,312\n",
        "    \n",
        "    8. Cantidad total de neuronas de capa: 1,000\n",
        "       Parámetros: 4,097,000\n",
        " \n",
        "La capa 3 y 4 llevan 384 filtros, siendo las capas con mayor cantidad de filtros. Por otro lado, la primera capa densa es la que tiene más parámetros, 37,752,832.\n",
        " \n",
        "Como mencioné anteoriormente, notamos que las capas de convolución (1 - 5) no aportan tantos parámetros a la red. Cada las neuronas que componen un filtro comparten los pesos, por lo que se reduce mucho la cantidad de pesos por capa. Esto es principalmente para que todas las neuronas de ese filtro se activen cuando encuentren el mismo patrón, es decir, cuando el producto punto entre el input y los pesos (iguales para todos) sea alto. De esta manera, cada mapa de activación es capas de detectar un patrón sobre su input. Luego, la siguiente capa de convolución va a encontrar patrones sobre estos patrones ya encontrados por cada filtro, construyendo sobre estos y encontrando objetos de mayer abstracción. En total, estas capas proveen 3,748,608 pesos.\n",
        "\n",
        "Luego, agregamos esta otras 3 capas de fully-connected donde se conectan todas las neuronas con todas. Esto implica el entrenamiento y almacenamiento de muchos pesos. Sumando las 3 capas densas obtenemos 58,631,144 pesos. Obviamente, esta suma es muy alta por lo que requiere alto entrenamiento y varios datos para poder obtener resultados relativamente buenos. \n",
        "\n",
        "La arquitectura de las capas de convolución es óptima porque necesita pocos parametros y aún asī es capas de detectar figuras de alto nivel de complejidad; las cuales luego serán clasificadas como: caras, objetos, humanos etc... Las 3 capas densas de clasificación aportan muchos parámetros, por lo que es costoso entrenarla. Creo que una buena práctica sería probar con clasificadores más simples (SVM o KNN) primero. Si se obtienen buenos resultados con esos no es necesario implementar estas 3 capas, pero puede darse el caso de que la cantidad de features sea demasiado alta comparado con la cantidad de datos causando que estos clasificadores no clasifiquen bien. En ese caso necesitaríamos estas capas densas que se comportan bien independiente de la dimensionalidad de los datos.\n"
      ]
    },
    {
      "metadata": {
        "id": "22OVKoj4-gst",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Actividad 7"
      ]
    },
    {
      "metadata": {
        "id": "B7jGSWfH-jbm",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Comenzamos cargando la data del directorio provisto"
      ]
    },
    {
      "metadata": {
        "id": "9BAYa6T1-luP",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import scipy.io as sio\n",
        "import os"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hg4AxSvF-mdL",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_mat_set(directory):\n",
        "    #Load the clases\n",
        "    cls = os.listdir(directory)\n",
        "    #Create empty arrays\n",
        "    X = []\n",
        "    Y = []\n",
        "    #Load the set\n",
        "    for cl in cls:\n",
        "        for mat in os.listdir(directory + '/' + cl):\n",
        "            X.append(sio.loadmat(directory + '/' + cl + '/' + mat)['stored'][0])\n",
        "            Y.append(cl)\n",
        "        \n",
        "    return X, Y\n",
        "\n",
        "X_train , Y_train = load_mat_set('./MIT-10-Classes/Feats/TrainSet')\n",
        "X_test, Y_test = load_mat_set('./MIT-10-Classes/Feats/TestSet')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "0THulDhP-nwF",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Print the dimensions of dataset\n",
        "print('X_train : {}'.format(len((X_train))))\n",
        "print('Y_train : {}'.format(len((Y_train))))\n",
        "print('X_test : {}'.format(len((X_test))))\n",
        "print('Y_test : {}'.format(len((Y_test))))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "P25k4mDO-qof",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Para esta activdad vamos a entrenar un SVM. Para el SVM, vamos a usar la libreria skilearn que provee un SVM ya implementado"
      ]
    },
    {
      "metadata": {
        "id": "24DzABzW-sss",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "from sklearn import svm"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "_ytLLpzo-vTw",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "#Instance a SVC model from sklearn. LinearSVC is a type of SVM for multiclass clasification.\n",
        "#LinearSVC trains n_classes models using one-vs-rest clasifiers (each model clasifies one class). \n",
        "#For classifying, every classifier is tested and the result with the higher probability is chosen.\n",
        "clf = svm.LinearSVC()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "iVaQEhJt-wqN",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "clf.fit(X_train, Y_train)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "5-xrF36f-y4k",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Primero, vamos a probar el modelo sobre el set de entrenamiento"
      ]
    },
    {
      "metadata": {
        "id": "ZyT9qaKp-0aO",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_train_pred = clf.predict(X_train)\n",
        "accuracy_score(Y_train, Y_train_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "undTNtyw-1v9",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "El clasificador tiene 100% efectividad sobre el set de entrenamiento. Esto podría indicar que el modelo calló en over-fitting, como mencionamos anteriormente, esto podría ocurrir porque la dimensioón de los datos - 4096 - es mucho mayor que la cantidad de datos - 799 -. Para verificar esto, veamos el rendimiento sobre el set de test"
      ]
    },
    {
      "metadata": {
        "id": "3QWSl-Cq-3E9",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "Y_pred = clf.predict(X_test)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "OX5mjmH0-4jd",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "accuracy_score(Y_test, Y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "hQYDpce9-6Lb",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Podemos notar que tiene una accuracy score de 97%, lo que es bastante bueno. Como se parecen ambos rendimientos, podemos descartar el hecho de que el modelo se over-fittio porque efectivamente pudo clasificar muy bien el set de test. Adicionalmente mostramos la matriz de confusión"
      ]
    },
    {
      "metadata": {
        "id": "9ObNviT6-73Q",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "confusion_matrix(Y_test, Y_pred)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "apwln9rp-9qe",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Actividad 8"
      ]
    },
    {
      "metadata": {
        "id": "oFdsRDAz_A_U",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "Comenzamos compilando el modelo creado. Vamos a usar la función de perdida categorical_crossentropy que nos permite clasificar multiples clases . Vamos a usar el optimizador adam porque hemos visto en otras CNN que funciona muy bien."
      ]
    },
    {
      "metadata": {
        "id": "ON_XvRAZ_E3p",
        "colab_type": "text"
      },
      "cell_type": "markdown",
      "source": [
        "La estructura de AlexNet que haciamos creado anteriormente realmente no nos funciona para este set de datos. Nosotros habiamos creado una capa densa al final que tenia 1000 neuronas, es decir, que clasificaba 1000 categorias. El dataset MIT-10-Classes contiene solo 10 clases, por lo que debemos remover esa ultima capa y volver a agregar una densa de solo 10 neuronas:"
      ]
    },
    {
      "metadata": {
        "id": "EY_0dC4G_Jix",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "modelAlexNet.layers.pop()\n",
        "modelAlexNet.add(Dense(10, activation='softmax', kernel_initializer='glorot_uniform', use_bias=True))\n",
        "modelAlexNet.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "e0HIcPsonUHB",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "modelAlexNet.compile(optimizer=optimizers.Adam(lr=5e-4),\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "Ny0BECXfnXD_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "6cf5933c-657d-484c-c23c-206939afd723"
      },
      "cell_type": "code",
      "source": [
        "#Load the images\n",
        "train_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "train_generator = train_datagen.flow_from_directory(\n",
        "        './MIT-10-Classes/Imgs/TrainSetImgs',\n",
        "        target_size=(224, 224),\n",
        "        batch_size=32,\n",
        "        class_mode='categorical')\n"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found 799 images belonging to 10 classes.\n",
            "Found 201 images belonging to 10 classes.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "TIXHGaH7n6Mr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1754
        },
        "outputId": "ce167ac9-d1b8-496f-e67a-8adb47d35fec"
      },
      "cell_type": "code",
      "source": [
        "modelAlexNet.fit_generator(\n",
        "        train_generator,\n",
        "        steps_per_epoch = train_generator.samples / 32,\n",
        "        epochs=25,\n",
        "        verbose=1)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "25/24 [==============================] - 9s 340ms/step - loss: 3.0145 - acc: 0.1100\n",
            "Epoch 2/50\n",
            "25/24 [==============================] - 7s 275ms/step - loss: 2.1548 - acc: 0.2179\n",
            "Epoch 3/50\n",
            "25/24 [==============================] - 7s 274ms/step - loss: 2.0155 - acc: 0.2792\n",
            "Epoch 4/50\n",
            "25/24 [==============================] - 7s 272ms/step - loss: 1.9025 - acc: 0.3328\n",
            "Epoch 5/50\n",
            "25/24 [==============================] - 7s 275ms/step - loss: 1.7763 - acc: 0.3729\n",
            "Epoch 6/50\n",
            "25/24 [==============================] - 7s 274ms/step - loss: 1.6151 - acc: 0.4105\n",
            "Epoch 7/50\n",
            "25/24 [==============================] - 7s 274ms/step - loss: 1.5132 - acc: 0.4705\n",
            "Epoch 8/50\n",
            "25/24 [==============================] - 7s 274ms/step - loss: 1.4552 - acc: 0.5005\n",
            "Epoch 9/50\n",
            "14/24 [===============>..............] - ETA: 3s - loss: 1.2674 - acc: 0.5861"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25/24 [==============================] - 7s 273ms/step - loss: 1.2696 - acc: 0.5795\n",
            "Epoch 10/50\n",
            "25/24 [==============================] - 7s 273ms/step - loss: 1.1245 - acc: 0.6144\n",
            "Epoch 11/50\n",
            "25/24 [==============================] - 6s 255ms/step - loss: 0.8619 - acc: 0.6971\n",
            "Epoch 12/50\n",
            "25/24 [==============================] - 7s 277ms/step - loss: 0.7394 - acc: 0.7648\n",
            "Epoch 13/50\n",
            "25/24 [==============================] - 7s 273ms/step - loss: 0.7013 - acc: 0.7748\n",
            "Epoch 14/50\n",
            "25/24 [==============================] - 7s 273ms/step - loss: 0.5136 - acc: 0.8223\n",
            "Epoch 15/50\n",
            "25/24 [==============================] - 7s 271ms/step - loss: 0.4315 - acc: 0.8623\n",
            "Epoch 16/50\n",
            "25/24 [==============================] - 7s 272ms/step - loss: 0.4027 - acc: 0.8610\n",
            "Epoch 17/50\n",
            "16/24 [==================>...........] - ETA: 2s - loss: 0.3003 - acc: 0.9160"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25/24 [==============================] - 7s 273ms/step - loss: 0.2992 - acc: 0.9098\n",
            "Epoch 18/50\n",
            "25/24 [==============================] - 7s 274ms/step - loss: 0.2304 - acc: 0.9249\n",
            "Epoch 19/50\n",
            "25/24 [==============================] - 7s 273ms/step - loss: 0.2728 - acc: 0.9134\n",
            "Epoch 20/50\n",
            "25/24 [==============================] - 7s 272ms/step - loss: 0.4047 - acc: 0.8922\n",
            "Epoch 21/50\n",
            "25/24 [==============================] - 7s 274ms/step - loss: 0.3157 - acc: 0.9012\n",
            "Epoch 22/50\n",
            "25/24 [==============================] - 7s 273ms/step - loss: 0.2021 - acc: 0.9274\n",
            "Epoch 23/50\n",
            "25/24 [==============================] - 7s 274ms/step - loss: 0.1527 - acc: 0.9499\n",
            "Epoch 24/50\n",
            "25/24 [==============================] - 7s 274ms/step - loss: 0.1705 - acc: 0.9475\n",
            "Epoch 25/50\n",
            "17/24 [===================>..........] - ETA: 2s - loss: 0.2273 - acc: 0.9337"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25/24 [==============================] - 7s 276ms/step - loss: 0.2240 - acc: 0.9312\n",
            "Epoch 26/50\n",
            "25/24 [==============================] - 7s 274ms/step - loss: 0.2176 - acc: 0.9448\n",
            "Epoch 27/50\n",
            "25/24 [==============================] - 7s 273ms/step - loss: 0.2533 - acc: 0.9337\n",
            "Epoch 28/50\n",
            "25/24 [==============================] - 7s 271ms/step - loss: 0.1786 - acc: 0.9474\n",
            "Epoch 29/50\n",
            "25/24 [==============================] - 7s 276ms/step - loss: 0.1251 - acc: 0.9637\n",
            "Epoch 30/50\n",
            "25/24 [==============================] - 7s 272ms/step - loss: 0.1669 - acc: 0.9500\n",
            "Epoch 31/50\n",
            "25/24 [==============================] - 7s 272ms/step - loss: 0.1519 - acc: 0.9500\n",
            "Epoch 32/50\n",
            "25/24 [==============================] - 7s 273ms/step - loss: 0.0859 - acc: 0.9737\n",
            "Epoch 33/50\n",
            "16/24 [==================>...........] - ETA: 2s - loss: 0.0783 - acc: 0.9746"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25/24 [==============================] - 7s 273ms/step - loss: 0.0705 - acc: 0.9787\n",
            "Epoch 34/50\n",
            "25/24 [==============================] - 7s 274ms/step - loss: 0.1080 - acc: 0.9687\n",
            "Epoch 35/50\n",
            "25/24 [==============================] - 7s 275ms/step - loss: 0.2308 - acc: 0.9450\n",
            "Epoch 36/50\n",
            "25/24 [==============================] - 7s 272ms/step - loss: 0.2349 - acc: 0.9412\n",
            "Epoch 37/50\n",
            "25/24 [==============================] - 7s 271ms/step - loss: 0.1962 - acc: 0.9412\n",
            "Epoch 38/50\n",
            "25/24 [==============================] - 7s 273ms/step - loss: 0.2061 - acc: 0.9448\n",
            "Epoch 39/50\n",
            "25/24 [==============================] - 7s 268ms/step - loss: 0.1793 - acc: 0.9487\n",
            "Epoch 40/50\n",
            "25/24 [==============================] - 7s 270ms/step - loss: 0.0557 - acc: 0.9812\n",
            "Epoch 41/50\n",
            "16/24 [==================>...........] - ETA: 2s - loss: 0.1019 - acc: 0.9726"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25/24 [==============================] - 7s 272ms/step - loss: 0.0999 - acc: 0.9700\n",
            "Epoch 42/50\n",
            "25/24 [==============================] - 7s 271ms/step - loss: 0.1116 - acc: 0.9700\n",
            "Epoch 43/50\n",
            "25/24 [==============================] - 7s 271ms/step - loss: 0.1471 - acc: 0.9687\n",
            "Epoch 44/50\n",
            "25/24 [==============================] - 7s 276ms/step - loss: 0.2206 - acc: 0.9411\n",
            "Epoch 45/50\n",
            "25/24 [==============================] - 7s 273ms/step - loss: 0.2958 - acc: 0.9387\n",
            "Epoch 46/50\n",
            "25/24 [==============================] - 7s 280ms/step - loss: 0.1771 - acc: 0.9486\n",
            "Epoch 47/50\n",
            "25/24 [==============================] - 7s 278ms/step - loss: 0.1990 - acc: 0.9575\n",
            "Epoch 48/50\n",
            "25/24 [==============================] - 7s 278ms/step - loss: 0.1885 - acc: 0.9625\n",
            "Epoch 49/50\n",
            "17/24 [===================>..........] - ETA: 2s - loss: 0.1912 - acc: 0.9593"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "25/24 [==============================] - 7s 277ms/step - loss: 0.1554 - acc: 0.9636\n",
            "Epoch 50/50\n",
            "25/24 [==============================] - 7s 280ms/step - loss: 0.1021 - acc: 0.9661\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f4fa158eda0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "metadata": {
        "id": "pHrykj7ln8D4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "016a0782-a5ce-432c-ad77-f7c78e02789f"
      },
      "cell_type": "code",
      "source": [
        "print(\"Saving Model\")\n",
        "modelAlexNet.save('modelAlexNet.h5')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Saving Model\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "abjE9z8XrKZm",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "import scipy.io as sio\n",
        "import numpy as np\n",
        "import cv2\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "from sklearn.preprocessing import LabelEncoder"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "XD1fvsogrMft",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "def load_test_set(directory):\n",
        "    #Load the clases\n",
        "    cls = os.listdir(directory)\n",
        "    #Create empty arrays\n",
        "    X = []\n",
        "    Y = []\n",
        "    #Load the set\n",
        "    for cl in cls:\n",
        "        for img in os.listdir(directory + '/' + cl):\n",
        "            img_arr = img_to_array(load_img(directory + '/' + cl + '/' + img))\n",
        "            resized = cv2.resize(img_arr, (224, 224))\n",
        "            X.append(resized)\n",
        "            Y.append(cl)\n",
        "    return np.array(X), np.array(Y)\n",
        "\n",
        "X_test, Y_test_string = load_test_set('./MIT-10-Classes/Imgs/TestSetImgs')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "EO0vMkCOz8U-",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        "# Convert string classes to vector of dim (1,10). Vector has a 1 on the\n",
        "# corresponding class and 0 on the rest.\n",
        "encoder = LabelEncoder()\n",
        "encoder.fit(Y_test_string)\n",
        "encoded_Y = encoder.transform(Y_test_string)\n",
        "Y_test = to_categorical(encoded_Y)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "metadata": {
        "id": "1N_fuu4QvrTP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "608dd8af-75ac-4f69-9e65-bc4faa7b9613"
      },
      "cell_type": "code",
      "source": [
        "Y_pred = modelAlexNet.predict(X_test)\n",
        "res = 0\n",
        "for i in range(Y_pred.shape[0]):\n",
        "  if np.array_equal(Y_pred[i], Y_test[i]) == True:\n",
        "    res += 1\n",
        "print(res/Y_pred.shape[0])"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.19900497512437812\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "metadata": {
        "id": "KA-D8gP_vt7w",
        "colab_type": "code",
        "colab": {}
      },
      "cell_type": "code",
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}